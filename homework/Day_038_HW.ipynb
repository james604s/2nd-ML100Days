{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [作業重點]\n",
    "使用 Sklearn 中的線性迴歸模型，來訓練各種資料集，務必了解送進去模型訓練的**資料型態**為何，也請了解模型中各項參數的意義"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業\n",
    "試著使用 sklearn datasets 的其他資料集 (wine, boston, ...)，來訓練自己的線性迴歸模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HINT: 注意 label 的型態，確定資料集的目標是分類還是回歸，在使用正確的模型訓練！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n",
    "from sklearn.datasets import load_boston, load_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "[[6.3200e-03 1.8000e+01 2.3100e+00 ... 1.5300e+01 3.9690e+02 4.9800e+00]\n",
      " [2.7310e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9690e+02 9.1400e+00]\n",
      " [2.7290e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9283e+02 4.0300e+00]\n",
      " ...\n",
      " [6.0760e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 5.6400e+00]\n",
      " [1.0959e-01 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9345e+02 6.4800e+00]\n",
      " [4.7410e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 7.8800e+00]]\n",
      "--------------------------\n",
      "['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
      " 'B' 'LSTAT']\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "boston = datasets.load_boston()\n",
    "print('--------------------------')\n",
    "print(boston.data)\n",
    "print('--------------------------')\n",
    "print(boston['feature_names'])\n",
    "print('--------------------------')\n",
    "boston_2 = pd.DataFrame(boston['data'], columns = boston['feature_names'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>0.01870</td>\n",
       "      <td>85.0</td>\n",
       "      <td>4.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.429</td>\n",
       "      <td>6.516</td>\n",
       "      <td>27.7</td>\n",
       "      <td>8.5353</td>\n",
       "      <td>4.0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>17.9</td>\n",
       "      <td>392.43</td>\n",
       "      <td>6.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>0.52693</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.504</td>\n",
       "      <td>8.725</td>\n",
       "      <td>83.0</td>\n",
       "      <td>2.8944</td>\n",
       "      <td>8.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>17.4</td>\n",
       "      <td>382.00</td>\n",
       "      <td>4.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>14.23620</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693</td>\n",
       "      <td>6.343</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.5741</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>20.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>0.11329</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428</td>\n",
       "      <td>6.897</td>\n",
       "      <td>54.3</td>\n",
       "      <td>6.3361</td>\n",
       "      <td>6.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>391.25</td>\n",
       "      <td>11.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.489</td>\n",
       "      <td>7.079</td>\n",
       "      <td>63.1</td>\n",
       "      <td>3.4145</td>\n",
       "      <td>2.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.06</td>\n",
       "      <td>5.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>0.76162</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.647</td>\n",
       "      <td>5.560</td>\n",
       "      <td>62.8</td>\n",
       "      <td>1.9865</td>\n",
       "      <td>5.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>392.40</td>\n",
       "      <td>10.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>0.02498</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.518</td>\n",
       "      <td>6.540</td>\n",
       "      <td>59.7</td>\n",
       "      <td>6.2669</td>\n",
       "      <td>1.0</td>\n",
       "      <td>422.0</td>\n",
       "      <td>15.9</td>\n",
       "      <td>389.96</td>\n",
       "      <td>8.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.25179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.570</td>\n",
       "      <td>98.1</td>\n",
       "      <td>3.7979</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>376.57</td>\n",
       "      <td>21.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0.08221</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.431</td>\n",
       "      <td>6.957</td>\n",
       "      <td>6.8</td>\n",
       "      <td>8.9067</td>\n",
       "      <td>7.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>19.1</td>\n",
       "      <td>386.09</td>\n",
       "      <td>3.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>13.52220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.631</td>\n",
       "      <td>3.863</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.5106</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>131.42</td>\n",
       "      <td>13.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRIM    ZN  INDUS  CHAS    NOX     RM    AGE     DIS   RAD    TAX  \\\n",
       "347   0.01870  85.0   4.15   0.0  0.429  6.516   27.7  8.5353   4.0  351.0   \n",
       "225   0.52693   0.0   6.20   0.0  0.504  8.725   83.0  2.8944   8.0  307.0   \n",
       "401  14.23620   0.0  18.10   0.0  0.693  6.343  100.0  1.5741  24.0  666.0   \n",
       "240   0.11329  30.0   4.93   0.0  0.428  6.897   54.3  6.3361   6.0  300.0   \n",
       "89    0.05302   0.0   3.41   0.0  0.489  7.079   63.1  3.4145   2.0  270.0   \n",
       "265   0.76162  20.0   3.97   0.0  0.647  5.560   62.8  1.9865   5.0  264.0   \n",
       "342   0.02498   0.0   1.89   0.0  0.518  6.540   59.7  6.2669   1.0  422.0   \n",
       "20    1.25179   0.0   8.14   0.0  0.538  5.570   98.1  3.7979   4.0  307.0   \n",
       "252   0.08221  22.0   5.86   0.0  0.431  6.957    6.8  8.9067   7.0  330.0   \n",
       "367  13.52220   0.0  18.10   0.0  0.631  3.863  100.0  1.5106  24.0  666.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "347     17.9  392.43   6.36  \n",
       "225     17.4  382.00   4.63  \n",
       "401     20.2  396.90  20.32  \n",
       "240     16.6  391.25  11.38  \n",
       "89      17.8  396.06   5.70  \n",
       "265     13.0  392.40  10.45  \n",
       "342     15.9  389.96   8.65  \n",
       "20      21.0  376.57  21.02  \n",
       "252     19.1  386.09   3.53  \n",
       "367     20.2  131.42  13.33  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#整個資料集讀取近來的方法\n",
    "boston_2 = pd.DataFrame(boston['data'], columns = boston['feature_names'])\n",
    "boston_2.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 13 columns):\n",
      "CRIM       506 non-null float64\n",
      "ZN         506 non-null float64\n",
      "INDUS      506 non-null float64\n",
      "CHAS       506 non-null float64\n",
      "NOX        506 non-null float64\n",
      "RM         506 non-null float64\n",
      "AGE        506 non-null float64\n",
      "DIS        506 non-null float64\n",
      "RAD        506 non-null float64\n",
      "TAX        506 non-null float64\n",
      "PTRATIO    506 non-null float64\n",
      "B          506 non-null float64\n",
      "LSTAT      506 non-null float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 51.5 KB\n"
     ]
    }
   ],
   "source": [
    "#無遺失值，皆為浮點數。\n",
    "boston_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (506, 1)\n"
     ]
    }
   ],
   "source": [
    "# 讀取波士頓資料集\n",
    "boston = datasets.load_boston()\n",
    "\n",
    "# 為方便視覺化，我們只使用資料集中的 1 個 feature (column)\n",
    "X = boston.data[:, np.newaxis, 6]\n",
    "print(\"Data shape: \", X.shape) # 可以看見有 506 筆資料與我們取出的其中一個 feature\n",
    "\n",
    "# 切分訓練集/測試集\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, boston.target, test_size=0.1, random_state=4)\n",
    "\n",
    "# 建立一個線性回歸模型\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# 將訓練資料丟進去模型訓練\n",
    "regr.fit(x_train, y_train)\n",
    "\n",
    "# 將測試資料丟進模型得到預測結果\n",
    "y_pred = regr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取 Boston 資料\n",
    "boston = load_boston()\n",
    "# 切分訓練集/測試集\n",
    "x_train, x_test, y_train, y_test = train_test_split(boston.data, boston.target, test_size=0.1, random_state=4)\n",
    "\n",
    "# 建立一個線性回歸模型\n",
    "regr = LinearRegression()\n",
    "\n",
    "# 將訓練資料丟進去模型訓練\n",
    "regr.fit(x_train, y_train)\n",
    "\n",
    "# 將測試資料丟進模型得到預測結果\n",
    "y_pred = regr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11.46030778, 26.80269335, 17.43478925, 17.5563101 , 37.39156424,\n",
       "       25.07675556, 31.05825852, 20.30845531, 19.66757374, 22.82655375,\n",
       "       28.47083056, 28.53331605, 18.72883256, 33.11375161, 21.34282974,\n",
       "       15.20554693, 21.57309275, 10.92841589, 11.69603405, 13.54311508,\n",
       "        5.07126801, 17.40464043, 20.69379268, 22.72981238, 16.4634139 ,\n",
       "       20.42666271, 17.53377349, 14.22644356, 21.56292745, 17.33136115,\n",
       "       14.28888479, 23.92829804, 34.31523522, 22.03799035, 17.47895779,\n",
       "       20.20386005, 30.70896335, 35.21599528, 24.07063567, 24.51445184,\n",
       "       36.77425366, 33.15265201, 19.67545976, 31.93505104, 33.55222906,\n",
       "       25.59147737, 40.59239607, 17.99555017, 19.92780188, 23.65319423,\n",
       "       33.48950986])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 17.04\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "[[1.423e+01 1.710e+00 2.430e+00 ... 1.040e+00 3.920e+00 1.065e+03]\n",
      " [1.320e+01 1.780e+00 2.140e+00 ... 1.050e+00 3.400e+00 1.050e+03]\n",
      " [1.316e+01 2.360e+00 2.670e+00 ... 1.030e+00 3.170e+00 1.185e+03]\n",
      " ...\n",
      " [1.327e+01 4.280e+00 2.260e+00 ... 5.900e-01 1.560e+00 8.350e+02]\n",
      " [1.317e+01 2.590e+00 2.370e+00 ... 6.000e-01 1.620e+00 8.400e+02]\n",
      " [1.413e+01 4.100e+00 2.740e+00 ... 6.100e-01 1.600e+00 5.600e+02]]\n",
      "--------------------------\n",
      "['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "--------------------------\n",
      "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
      "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
      "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
      "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
      "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
      "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
      "5      14.20        1.76  2.45               15.2      112.0           3.27   \n",
      "6      14.39        1.87  2.45               14.6       96.0           2.50   \n",
      "7      14.06        2.15  2.61               17.6      121.0           2.60   \n",
      "8      14.83        1.64  2.17               14.0       97.0           2.80   \n",
      "9      13.86        1.35  2.27               16.0       98.0           2.98   \n",
      "10     14.10        2.16  2.30               18.0      105.0           2.95   \n",
      "11     14.12        1.48  2.32               16.8       95.0           2.20   \n",
      "12     13.75        1.73  2.41               16.0       89.0           2.60   \n",
      "13     14.75        1.73  2.39               11.4       91.0           3.10   \n",
      "14     14.38        1.87  2.38               12.0      102.0           3.30   \n",
      "15     13.63        1.81  2.70               17.2      112.0           2.85   \n",
      "16     14.30        1.92  2.72               20.0      120.0           2.80   \n",
      "17     13.83        1.57  2.62               20.0      115.0           2.95   \n",
      "18     14.19        1.59  2.48               16.5      108.0           3.30   \n",
      "19     13.64        3.10  2.56               15.2      116.0           2.70   \n",
      "20     14.06        1.63  2.28               16.0      126.0           3.00   \n",
      "21     12.93        3.80  2.65               18.6      102.0           2.41   \n",
      "22     13.71        1.86  2.36               16.6      101.0           2.61   \n",
      "23     12.85        1.60  2.52               17.8       95.0           2.48   \n",
      "24     13.50        1.81  2.61               20.0       96.0           2.53   \n",
      "25     13.05        2.05  3.22               25.0      124.0           2.63   \n",
      "26     13.39        1.77  2.62               16.1       93.0           2.85   \n",
      "27     13.30        1.72  2.14               17.0       94.0           2.40   \n",
      "28     13.87        1.90  2.80               19.4      107.0           2.95   \n",
      "29     14.02        1.68  2.21               16.0       96.0           2.65   \n",
      "..       ...         ...   ...                ...        ...            ...   \n",
      "148    13.32        3.24  2.38               21.5       92.0           1.93   \n",
      "149    13.08        3.90  2.36               21.5      113.0           1.41   \n",
      "150    13.50        3.12  2.62               24.0      123.0           1.40   \n",
      "151    12.79        2.67  2.48               22.0      112.0           1.48   \n",
      "152    13.11        1.90  2.75               25.5      116.0           2.20   \n",
      "153    13.23        3.30  2.28               18.5       98.0           1.80   \n",
      "154    12.58        1.29  2.10               20.0      103.0           1.48   \n",
      "155    13.17        5.19  2.32               22.0       93.0           1.74   \n",
      "156    13.84        4.12  2.38               19.5       89.0           1.80   \n",
      "157    12.45        3.03  2.64               27.0       97.0           1.90   \n",
      "158    14.34        1.68  2.70               25.0       98.0           2.80   \n",
      "159    13.48        1.67  2.64               22.5       89.0           2.60   \n",
      "160    12.36        3.83  2.38               21.0       88.0           2.30   \n",
      "161    13.69        3.26  2.54               20.0      107.0           1.83   \n",
      "162    12.85        3.27  2.58               22.0      106.0           1.65   \n",
      "163    12.96        3.45  2.35               18.5      106.0           1.39   \n",
      "164    13.78        2.76  2.30               22.0       90.0           1.35   \n",
      "165    13.73        4.36  2.26               22.5       88.0           1.28   \n",
      "166    13.45        3.70  2.60               23.0      111.0           1.70   \n",
      "167    12.82        3.37  2.30               19.5       88.0           1.48   \n",
      "168    13.58        2.58  2.69               24.5      105.0           1.55   \n",
      "169    13.40        4.60  2.86               25.0      112.0           1.98   \n",
      "170    12.20        3.03  2.32               19.0       96.0           1.25   \n",
      "171    12.77        2.39  2.28               19.5       86.0           1.39   \n",
      "172    14.16        2.51  2.48               20.0       91.0           1.68   \n",
      "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
      "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
      "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
      "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
      "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
      "\n",
      "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
      "0          3.06                  0.28             2.29         5.640000  1.04   \n",
      "1          2.76                  0.26             1.28         4.380000  1.05   \n",
      "2          3.24                  0.30             2.81         5.680000  1.03   \n",
      "3          3.49                  0.24             2.18         7.800000  0.86   \n",
      "4          2.69                  0.39             1.82         4.320000  1.04   \n",
      "5          3.39                  0.34             1.97         6.750000  1.05   \n",
      "6          2.52                  0.30             1.98         5.250000  1.02   \n",
      "7          2.51                  0.31             1.25         5.050000  1.06   \n",
      "8          2.98                  0.29             1.98         5.200000  1.08   \n",
      "9          3.15                  0.22             1.85         7.220000  1.01   \n",
      "10         3.32                  0.22             2.38         5.750000  1.25   \n",
      "11         2.43                  0.26             1.57         5.000000  1.17   \n",
      "12         2.76                  0.29             1.81         5.600000  1.15   \n",
      "13         3.69                  0.43             2.81         5.400000  1.25   \n",
      "14         3.64                  0.29             2.96         7.500000  1.20   \n",
      "15         2.91                  0.30             1.46         7.300000  1.28   \n",
      "16         3.14                  0.33             1.97         6.200000  1.07   \n",
      "17         3.40                  0.40             1.72         6.600000  1.13   \n",
      "18         3.93                  0.32             1.86         8.700000  1.23   \n",
      "19         3.03                  0.17             1.66         5.100000  0.96   \n",
      "20         3.17                  0.24             2.10         5.650000  1.09   \n",
      "21         2.41                  0.25             1.98         4.500000  1.03   \n",
      "22         2.88                  0.27             1.69         3.800000  1.11   \n",
      "23         2.37                  0.26             1.46         3.930000  1.09   \n",
      "24         2.61                  0.28             1.66         3.520000  1.12   \n",
      "25         2.68                  0.47             1.92         3.580000  1.13   \n",
      "26         2.94                  0.34             1.45         4.800000  0.92   \n",
      "27         2.19                  0.27             1.35         3.950000  1.02   \n",
      "28         2.97                  0.37             1.76         4.500000  1.25   \n",
      "29         2.33                  0.26             1.98         4.700000  1.04   \n",
      "..          ...                   ...              ...              ...   ...   \n",
      "148        0.76                  0.45             1.25         8.420000  0.55   \n",
      "149        1.39                  0.34             1.14         9.400000  0.57   \n",
      "150        1.57                  0.22             1.25         8.600000  0.59   \n",
      "151        1.36                  0.24             1.26        10.800000  0.48   \n",
      "152        1.28                  0.26             1.56         7.100000  0.61   \n",
      "153        0.83                  0.61             1.87        10.520000  0.56   \n",
      "154        0.58                  0.53             1.40         7.600000  0.58   \n",
      "155        0.63                  0.61             1.55         7.900000  0.60   \n",
      "156        0.83                  0.48             1.56         9.010000  0.57   \n",
      "157        0.58                  0.63             1.14         7.500000  0.67   \n",
      "158        1.31                  0.53             2.70        13.000000  0.57   \n",
      "159        1.10                  0.52             2.29        11.750000  0.57   \n",
      "160        0.92                  0.50             1.04         7.650000  0.56   \n",
      "161        0.56                  0.50             0.80         5.880000  0.96   \n",
      "162        0.60                  0.60             0.96         5.580000  0.87   \n",
      "163        0.70                  0.40             0.94         5.280000  0.68   \n",
      "164        0.68                  0.41             1.03         9.580000  0.70   \n",
      "165        0.47                  0.52             1.15         6.620000  0.78   \n",
      "166        0.92                  0.43             1.46        10.680000  0.85   \n",
      "167        0.66                  0.40             0.97        10.260000  0.72   \n",
      "168        0.84                  0.39             1.54         8.660000  0.74   \n",
      "169        0.96                  0.27             1.11         8.500000  0.67   \n",
      "170        0.49                  0.40             0.73         5.500000  0.66   \n",
      "171        0.51                  0.48             0.64         9.899999  0.57   \n",
      "172        0.70                  0.44             1.24         9.700000  0.62   \n",
      "173        0.61                  0.52             1.06         7.700000  0.64   \n",
      "174        0.75                  0.43             1.41         7.300000  0.70   \n",
      "175        0.69                  0.43             1.35        10.200000  0.59   \n",
      "176        0.68                  0.53             1.46         9.300000  0.60   \n",
      "177        0.76                  0.56             1.35         9.200000  0.61   \n",
      "\n",
      "     od280/od315_of_diluted_wines  proline  \n",
      "0                            3.92   1065.0  \n",
      "1                            3.40   1050.0  \n",
      "2                            3.17   1185.0  \n",
      "3                            3.45   1480.0  \n",
      "4                            2.93    735.0  \n",
      "5                            2.85   1450.0  \n",
      "6                            3.58   1290.0  \n",
      "7                            3.58   1295.0  \n",
      "8                            2.85   1045.0  \n",
      "9                            3.55   1045.0  \n",
      "10                           3.17   1510.0  \n",
      "11                           2.82   1280.0  \n",
      "12                           2.90   1320.0  \n",
      "13                           2.73   1150.0  \n",
      "14                           3.00   1547.0  \n",
      "15                           2.88   1310.0  \n",
      "16                           2.65   1280.0  \n",
      "17                           2.57   1130.0  \n",
      "18                           2.82   1680.0  \n",
      "19                           3.36    845.0  \n",
      "20                           3.71    780.0  \n",
      "21                           3.52    770.0  \n",
      "22                           4.00   1035.0  \n",
      "23                           3.63   1015.0  \n",
      "24                           3.82    845.0  \n",
      "25                           3.20    830.0  \n",
      "26                           3.22   1195.0  \n",
      "27                           2.77   1285.0  \n",
      "28                           3.40    915.0  \n",
      "29                           3.59   1035.0  \n",
      "..                            ...      ...  \n",
      "148                          1.62    650.0  \n",
      "149                          1.33    550.0  \n",
      "150                          1.30    500.0  \n",
      "151                          1.47    480.0  \n",
      "152                          1.33    425.0  \n",
      "153                          1.51    675.0  \n",
      "154                          1.55    640.0  \n",
      "155                          1.48    725.0  \n",
      "156                          1.64    480.0  \n",
      "157                          1.73    880.0  \n",
      "158                          1.96    660.0  \n",
      "159                          1.78    620.0  \n",
      "160                          1.58    520.0  \n",
      "161                          1.82    680.0  \n",
      "162                          2.11    570.0  \n",
      "163                          1.75    675.0  \n",
      "164                          1.68    615.0  \n",
      "165                          1.75    520.0  \n",
      "166                          1.56    695.0  \n",
      "167                          1.75    685.0  \n",
      "168                          1.80    750.0  \n",
      "169                          1.92    630.0  \n",
      "170                          1.83    510.0  \n",
      "171                          1.63    470.0  \n",
      "172                          1.71    660.0  \n",
      "173                          1.74    740.0  \n",
      "174                          1.56    750.0  \n",
      "175                          1.56    835.0  \n",
      "176                          1.62    840.0  \n",
      "177                          1.60    560.0  \n",
      "\n",
      "[178 rows x 13 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 178 entries, 0 to 177\n",
      "Data columns (total 13 columns):\n",
      "alcohol                         178 non-null float64\n",
      "malic_acid                      178 non-null float64\n",
      "ash                             178 non-null float64\n",
      "alcalinity_of_ash               178 non-null float64\n",
      "magnesium                       178 non-null float64\n",
      "total_phenols                   178 non-null float64\n",
      "flavanoids                      178 non-null float64\n",
      "nonflavanoid_phenols            178 non-null float64\n",
      "proanthocyanins                 178 non-null float64\n",
      "color_intensity                 178 non-null float64\n",
      "hue                             178 non-null float64\n",
      "od280/od315_of_diluted_wines    178 non-null float64\n",
      "proline                         178 non-null float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 18.2 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "a = datasets.load_wine()\n",
    "a\n",
    "\n",
    "a = datasets.load_wine()\n",
    "print('--------------------------')\n",
    "print(a.data)\n",
    "print('--------------------------')\n",
    "print(a['feature_names'])\n",
    "print('--------------------------')\n",
    "a_2 = pd.DataFrame(a['data'], columns = a['feature_names'])\n",
    "print(a_2)\n",
    "print(a_2.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/squid504s/anaconda3/envs/sqenv/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/squid504s/anaconda3/envs/sqenv/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# 讀取 wine 資料\n",
    "wine = load_wine()\n",
    "\n",
    "# 切分訓練集/測試集\n",
    "x_train, x_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.1, random_state=4)\n",
    "\n",
    "# 建立一個羅吉斯回歸模型\n",
    "regr = LogisticRegression()\n",
    "\n",
    "# 將訓練資料丟進去模型訓練\n",
    "regr.fit(x_train, y_train)\n",
    "\n",
    "# 將測試資料丟進模型得到預測結果\n",
    "y_pred = regr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
