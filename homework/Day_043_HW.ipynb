{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [作業重點]\n",
    "了解隨機森林改善了決策樹的什麼缺點？是用什麼方法改進的？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業\n",
    "\n",
    "閱讀以下兩篇文獻，了解隨機森林原理，並試著回答後續的思考問題\n",
    "- [隨機森林 (random forest) - 中文](http://hhtucode.blogspot.tw/2013/06/ml-random-forest.html)\n",
    "- [how random forest works - 英文](https://medium.com/@Synced/how-random-forest-algorithm-works-in-machine-learning-3c0fe15b6674)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. 隨機森林中的每一棵樹，是希望能夠\n",
    "\n",
    "    - 沒有任何限制，讓樹可以持續生長 (讓樹生成很深，讓模型變得複雜)\n",
    "    \n",
    "    - 不要過度生長，避免 Overfitting\n",
    "   隨機森林希望每棵樹都能夠盡量複雜，然後再通過投票的方式，處理過擬合的問題。因此希望每棵樹都能夠盡量的生長\n",
    "這是傳統的統計問題，採用取後放回的方式，抽取與資料量同樣大小的 N 筆資料，約會使用 63.2 % 的原生資料。\n",
    "    \n",
    "2. 假設總共有 N 筆資料，每棵樹用取後放回的方式抽了總共 N 筆資料生成，請問這棵樹大約使用了多少 % 不重複的原資料生成?\n",
    "hint: 0.632 bootstrap\n",
    "取後放回，抽取與資料同樣大小的 N 筆資料，大概會使用 63.2 % 的原生資料。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 隨機森林算法是一種監督分類算法。 \n",
    "* 森林中樹木的數量與可獲得的結果之間存在直接關係：樹木數量越多，結果越準確。 \n",
    "* 需要注意的是，創建森林與使用information gain 或 gain index approach 方法構建決策不同。\n",
    "* 隨機森林算法和決策樹算法的區別在於隨機森林中，找到根節點和分割特徵節點的過程將隨機運行。\n",
    "### 優點\n",
    "1. 它可以用於分類和回歸任務。 \n",
    "2. 過度擬合是一個可能使結果更糟的關鍵問題，但對於隨機森林算法，如果森林中有足夠的樹，分類器將不會過度擬合模型。 \n",
    "3. 隨機森林的分類器可以處理缺失值。\n",
    "4. 可以為隨機森林分類器建模分類值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part.1_RF的創建\n",
    "1. Randomly select “K” features from total “m” features where k << m\n",
    "2. Among the “K” features, calculate the node “d” using the best split point\n",
    "3. Split the node into daughter nodes using the best split\n",
    "4. Repeat the a to c steps until “l” number of nodes has been reached\n",
    "5. Build forest by repeating steps a to d for “n” number times to create “n” number of trees\n",
    "\n",
    "### Part.2_RF classify predict\n",
    "1. Takes the test features and use the rules of each randomly created decision tree to predict the outcome and stores the predicted outcome (target)\n",
    "2. Calculate the votes for each predicted target\n",
    "3. Consider the high voted predicted target as the final prediction from the random forest algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
